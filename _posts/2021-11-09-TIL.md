---
layout: post
title: "Celery"
date: 2021-11-09
categories: TIL Celery Redis
---

Celery, Redis 비동기 작업 큐(Queue)

현재 프로젝트 상황에서 업로드되는 과정에서 소요되는 시간이 사용자입장에서는 불편하여  
비동기 작업으로 따로 서버를 구축을 하여서 이용하면 어떨까해서 Celery에 대해 조사를 해보았다

Celery는 Worker와 Broker로 이루어져 있다

celery/worker.py
```python
CELERY_BROKER_URL = 'redis://localhost:6379/0'
BACKEND_URL = 'redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'

from __future__ import absolute_import, unicode_literals
from celery import Celery
from settings import CELERY_BROKER_URL, BACKEND_URL

app = Celery("celery_app",broker=CELERY_BROKER_URL, backend=BACKEND_URL)
```

celery/tasks.py
```python
from . import worker

@app.task
def add(x,y):
    return x+y
```

Celery 실행 명령어
`celery -A {file name} worker -I info`

celery-beat : 주기적으로 특정 프로세스를 동작시키기 위한 패키지

celery -A tasks worker --loglevel=info

-A: application ( = -app )  => 확장자를 제외하고 입력함. 만약 tasks.py 이면 tasks를 입력

worker 는 기본 명령어이며 worker 서버를 구동하라는 뜻이다.


schedule
```python
from celery.schedules import crontab
 
@app.task(bind=True)
def debug_task(self):
    print('Request: {0!r}'.format(self.request))
 
app.conf.beat_schedule = {
    'add-every-minute-contrab': {
        'task': 'multiply_two_numbers',
        'schedule': crontab(),  # 1분마다
        'args': (16, 16),
    },
    'add-every-5-seconds': {
        'task': 'multiply_two_numbers',
        'schedule': 5.0,  # 5초마다
        'args': (16, 16)
    },
    'add-every-30-seconds': {
        'task': 'tasks.add',
        'schedule': 30.0, # 30초마다
        'args': (16, 16)
    },
}
```