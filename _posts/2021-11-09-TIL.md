---
layout: post
title: "Celery 기초💬"
date: 2021-11-09
categories: TIL Celery Redis
---

![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/celery.png)

![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/celery_process.jpeg)

Celery, Redis 비동기 작업 큐(Queue)

현재 프로젝트 상황에서 업로드되는 과정에서 소요되는 시간이 사용자입장에서는 불편하여  
비동기 작업으로 따로 서버를 구축을 하여서 이용하면 어떨까해서 Celery에 대해 조사를 해보았다

Celery는 Worker와 Broker로 이루어져 있다

## celery config

```python
CELERY_BROKER_URL = 'redis://localhost:6379/0'
BACKEND_URL = 'redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'

from __future__ import absolute_import, unicode_literals
from celery import Celery
from settings import CELERY_BROKER_URL, BACKEND_URL

app = Celery("celery_app",broker=CELERY_BROKER_URL, backend=BACKEND_URL)
```

### app.config_from_object 활용하기

*celeryconfig.py*
```python
broker_url = 'redis://localhost:6379'
result_backend = 'redis://localhost:6379'
accept_content = ['pickle','json','application/x-python-serialize']
task_serializer = 'pickle'
result_serializer = 'pickle'
timezone = 'Asia/Seoul'
```

*celery_app/worker.py*
```python
from __future__ import absolute_import, unicode_literals
from celery import Celery

app = Celery('celery_app',include=['celery_app.tasks'])

app.config_from_object('celery_app.celeryconfig')
```

## Task
*celery_app/tasks.py*
```python
from celery_app.worker import app as celery_app

@celery_app.task
def add(x,y):
    return x+y
```

[Celery Task](https://docs.celeryproject.org/en/stable/userguide/tasks.html)

*※ Task Process 전달*
- Task function에 Process 전달을 하려면 해당 객체가 Celery 설정된 데이터형식에 직렬화가 가능해야한다
    - [Json](https://www.json.org/json-en.html) : JSON의 주요 단점은 문자열, 유니코드, 부동 소수점, Bool, 딕셔너리와 리스트와 같은 데이터 유형으로 제한된다는 것입니다. 
    소수점과 날짜 불가능 
    바이너리 데이터는 Base64 인코딩을 사용하여 전송되며, 기본 바이너리 유형이 지원되는 인코딩 형식에 비해 전송되는 데이터의 크기가 34% 증가합니다  
    그러나 데이터가 위의 제약 조건에 적합하고 언어 간 지원이 필요한 경우 JSON의 기본 설정이 가장 좋은 선택일 것입니다  
    - [pickle](https://docs.python.org/dev/library/pickle.html#module-pickle) : 내장된 모든 Python 데이터 유형(클래스 인스턴스 제외)
     바이너리 파일을 보낼 때 더 작은 메시지, JSON 처리에 비해 약간의 속도 향상을 지원합니다
    - [yaml](http://yaml.org/) : 더 많은 데이터 유형(날짜, 재귀 참조 등 포함)을 기본적으로 지원합니다    
    AML용 Python 라이브러리는 JSON용 라이브러리보다 약간 느립니다.  
    보다 표현적인 데이터 유형 집합이 필요하고 언어 간 호환성을 유지해야 하는 경우 YAML이 위의 것보다 더 적합할 수 있습니다.
    - [msgpack](http://msgpack.org/) :  msgpack은 JSON에 가까운 바이너리 직렬화 형식입니다.

## Celery 동작
*main.py*
```python
from celery_app.tasks import add

add.apply_async(args=[1,2], link=callback_handler, link_error=error_handler, ....)
# 기능을 추가할 수 있는 콜백함수를 인자값으로 넣을 수 있다
```

### Callback Function

*예시*
```python
@celery_app.task
def error_handler(request, exc, traceback):
    print('Task {0} raised exception: {1!r}\n{2!r}'.format(
          request.id, exc, traceback))

@celery_app.task
def callback_handler(response):
   print(f"Success file count :: {response}")
```

Celery 실행 명령어
`celery -A {file name} worker -I info`

worker와 beat 모두 실행  
`celery -A {file name}  worker -l info -B `
celery-beat : 주기적으로 특정 프로세스를 동작시키기 위한 패키지

-A: application ( = -app )  => 확장자를 제외하고 입력함. 만약 tasks.py 이면 tasks를 입력

worker 는 기본 명령어이며 worker 서버를 구동하라는 뜻이다.


## schedule

```python
from celery.schedules import crontab
 
@app.task(bind=True)
def debug_task(self):
    print('Request: {0!r}'.format(self.request))
 
app.conf.beat_schedule = {
    'add-every-minute-contrab': {
        'task': 'multiply_two_numbers',
        'schedule': crontab(),  # 1분마다
        'args': (16, 16),
    },
    'add-every-5-seconds': {
        'task': 'multiply_two_numbers',
        'schedule': 5.0,  # 5초마다
        'args': (16, 16)
    },
    'add-every-30-seconds': {
        'task': 'tasks.add',
        'schedule': 30.0, # 30초마다
        'args': (16, 16)
    },
}
```

## Celery monitor Tool
*Flower*
`pip install flower`  

- 작업 프로세스 상태
- 작업 프로세스 종료 및 다시시작
- 디테일한 API 관리
- Celery Monitoring

명령어  
`celery -A {file name} flower --address=localhost --port=5555`

## Redis
`apt install redis-server` 설치
`apt install redis-cli` 설치

`redis-cli ping` >> PONG  
연결 성공  

# Blocker
flask form data를 받는 과정에서 직렬화가 안되어서 task를 전달하지 못하는 상황이 있었다  
form data는 `werkzeug.datastructures.FileStorage`로 서버로 전달이 되었는데 해당 데이터 중 FileStorage.stream이 직렬화가 불가능하였다  
*_io.ByteIO Object는 pickle, json 직렬화가 불가능하다*  
데이터 객체를 분해시킨 뒤 `FileStorage.stream.read()`로 이진형식으로 바꾼뒤 형태들을 딕셔너리로 바꿔 전달을 하였더니 문제없이 해결을 하였다  
task 함수가 받으면 stream은 다시 io.BytesIO(fileStream)으로 BytesIO 객체로 변환하여 FileStorage 객체로 결합을 시켰다  

*main.py*
```python
.
.
.

format = {
        'stream': file.stream.read(),
        'name': file.name,
        'filename': file.filename,
        'content_type': file.content_type,
        'content_length': file.content_length,
        'headers': {header[0]: header[1] for header in file.headers}
    }
```
<br>

*task.py*
```python
from io import BytesIO
from werkzeug.datastructures import FileStorage

.
.
.

file['stream'] = io.BytesIO(file['stream'])
filestorage = FileStorage(**file)

file = Path(filestorage.filename)            
```
[참고 자료](https://newbedev.com/celery-task-in-flask-for-uploading-and-resizing-images-and-storing-it-to-amazon-s3)