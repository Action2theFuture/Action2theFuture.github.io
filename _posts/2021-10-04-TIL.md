---
layout: post
title: "DockerSwarm Error | Network"
date: 2021-10-04
categories: TIL Docker-machine DockerSwarm Error Network
---

# Error

## Error contents

터미널에서 확인한 Active된 컨테이너는 제대로 돌아가고 있는데 클라이언트단에서는 접속이 안되는 문제가 발생하였다  
이러한 문제를 해결하기 위해서 3일동안 고민을 많이 하였다  
처음에는 볼륨이 제대로 마운트되지 않아서 볼륨 경로를 확인를 하였고 django서버가 속한 컨테이너와 볼륨이 제대로 바인딩되어 있지 않아서 수정을 하였다  
그 후 다시 실행을 하였지만 django 서비스와 depends_on으로 연결된 데이터베이스의 빌드와 볼륨이 제대로 바인딩이 되어있지 않아서 데이버베이스도 수정을 하였다  
이제는 경로상으로 아무런 문제가 없었다  
또다른 문제가 발생하였다 에러사항도 나타나지 않고 클라이언트단에서 제대로 출력이 되었지만 데이터를 입력하게 되면 서버가 다운이 되는 상황이 발생하였다  
만약에 서버가 꺼지면 docker swarm으로 다른 컨테이너가 활성화가 되어서 서버가 다운이 되지 않아야 하는데 이러한 상황이 발생하였다  
원인을 찾아보니 나는 EC2 인스턴스 2개를 사용하고 있었는데 하나는 매니저 노드 하나는 워커 노드였다 매니저 노드는 용량이 50G이고 워커 노드는 8G였는데 docker swarm을 활성화 시키면  
무작위로 각 노드에 실행이 되는데 docker overlay가 11G가 이상의 용량을 차지하고 있어서 인스턴스가 감당이 안 되어서 docker sevice가 강제로 꺼져버리는 문제였다  
그래서 난 docker-compose.yml 설정에서 비교적 큰 용량을 차지하는 app서비스를 매니저 노드에 할당하였고 워커 노드는 볼륨을 늘려서 이 문제를 해결하였다

- **용량부족으로 생긴 Error**
  ![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/network.png)

- overy filesystem 용량
  ![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/overlay.png)

제대로 실행되겠다고 생각을 해서 다시 컨테이너를 실행하였지만 클라이언트단에서는 접속이 안 되어서 크롬 브라우저에 ERR_CONNECTION_REFUSED인 상태가 지속되었다  
Dockerswarm을 사용하면서 실행방법에 대해 알고만 있었지 이것이 어떻게 실행되는지는 정확히 알지 못해서 어느 부분을 건드려야될지 몰라서 너무 답답한 상황이었다  
각 컨테이너와 네트워크를 검사를 하고 로그를 보았다

- `docker service inspect 이미지 서비스`
- `docker inspect 컨테이너`
- `docker service logs 컨테이너`

- `docker network inspect 네트워크`

## docker inspect

- docker container 일부분

```
.
.
.
"NetworkSettings": {
            "Bridge": "",
            "SandboxID": "869cad22c938d04f231721be01ded18f6c7ed9768e05691d533b9bafb13c8aa4",
            "HairpinMode": false,
            "LinkLocalIPv6Address": "",
            "LinkLocalIPv6PrefixLen": 0,
            "Ports": {
                "8000/tcp": null
            },
            .
            .
            .
```

- **Reason**

컨테이너를 검사를 해보니 네트워크 쪽에서 문제가 발생한 것을 알 수 있었다  
내부 컨테이너 포트와 외부 호스트OS 통신이 연결이 안 되어서 클라이언트에서 접속을 못 하는 문제였다  
터미널 상에서는 컨테이너가 문제 없이 돌아가지만 외부가 접속을 못하니 에러사항이 발생하지 않았던 것이었다

## Blocker 해결

초기에 설정된 app서버의 dockerfile은 python 환경에서 돌아가는 컨테이너를 빌드를 하였다
서버 환경을 처음부터 내가 원하는 환경으로 만들기 위해서 이미지를 우분투 이미지로 바꾸고
커맨드 입력을 쉘 스크립트 파일로 변경하였다

내부 컨테이너 포트 번호와 외부 네트워크 포트 번호와 제대로 연결을 명시하기 위해서 dockerfile로 설정하는 것보다는 쉘 스크립트로 내부 컨테이너의 포트를 지정을 해주고  
docker-compose.yml 파일로 외부 네트워크 포트와 내부 네트워크 포트를 바인딩 해주었다

- **Before**

```dockerfile
#./Dockerfile
FROM python:3.9
#기반이 될 이미지

# 작업디렉토리(default)설정
WORKDIR /usr/src/app

#현재 패키지 설치 정보를 도커 이미지에 복사
COPY requirements.txt ./
#설치정보를 읽어 들여서 패키지를 설치
RUN pip install -r requirements.txt

#현재경로에 존재하는 모든 소스파일을 이미지에 복사
COPY . .

EXPOSE 8000

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "drf_test.wsgi:application"]
# 컨테이너가 run이 되면 해당 커맨드가 실행이 된다
```

```yml
version: "3"
services:
  server:
    # docker compose build 반응하는 커맨드 구간
    image: tree0204/drf_tuto:0.1.0
    # dockerfile 경로
    build: ./
    # 볼륨 파일 경로 :르 이용하여 type을 bind로 설정
    volumes:
      - ./:/usr/src/app
    # basg 숼 커맨드 입력
    command:
      - bash
      - -c
      - |
        python manage.py collectstatic --no-input
        python manage.py migrate
    # 내부 포트 8000번과 외부 포트 8000번 연결
    ports:
      - 8000:8000
    # docker swarm 반응하는 커맨드
    deploy:
      # docker swarm으로 띄울 서버 개수
      replicas: 2
      # 해당 서비스가 할당되는 노드 지정
      placement:
        constraints: [node.role==manager]
      # 사용한 메모리 자원 할당
      resources:
        limits:
          memory: 10M
        reservations:
          memory: 10M
          cpus: "0.1"
      # 서버가 다운이 될시 재시작할 설정 커맨드
      restart_policy:
        condition: on-failure
        delay: 2s
        # 예비 컨테이너
        max_attempts: 2

  sqlite3:
    image: nouchka/sqlite3:latest
    stdin_open: true
    tty: true
    volumes:
      - /db=./db.sqlite3
    deploy:
      replicas: 2
```

- **After**

```dockerfile
FROM ubuntu:20.04

RUN apt-get update && apt-get install -y
RUN apt-get install -y python3.9
RUN apt-get install -y python3-pip

COPY ./docker-entrypoint.sh /docker-entrypoint.sh
# docker.entrypoin.sh 쉘을 복사
RUN chmod +x /docker-entrypoint.sh
# 스크립트 파일에 대한 권한 부여
COPY . /app

WORKDIR /app

RUN pip install -r requirements.txt

ENTRYPOINT ["bash","/app/docker-entrypoint.sh"]
# 쉘 스크립트 실행
```

```shell
#!/bin/bash

echo "Collect static files"
python manage.py collectstatic --noinput

# 데이터베이스 migrate
echo "Apply database migrations"
python manage.py migrate

# Start server
echo "Starting server"
gunicorn --bind 0.0.0.0:8000 drf_test.wsgi:application
```

```yml
version: "3"

services:
  server:
    # docekrfile 경로
    image: tree0204/drf_tuto:0.1.0
    build: ./
    volumes:
      - ./:/app
    ports:
      - 8000:8000
    # 각 컨테이너가 통신할 네트워크 이름
    networks:
      - network
    deploy:
      replicas: 3
      placement:
        constraints: [node.role==manager]
      resources:
        limits:
          memory: 20M
        reservations:
          memory: 20M
          cpus: "0.1"
      restart_policy:
        condition: on-failure
        delay: 2s
        max_attempts: 2

  sqlite3:
    image: nouchka/sqlite3:latest
    stdin_open: true
    tty: true
    volumes:
      - /db=./db.sqlite3
    # 각 컨테이너가 통신할 네트워크 이름
    networks:
      - network
    deploy:
      replicas: 2
      placement:
        constraints: [node.role==worker]

#각 컨테이너가 통신할 네트워크가 만들어진다
networks:
  network:
```

### Network

![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/ingressoverlay.png)

- **ingress network**

swarm init, join으로 자동으로 생성이 된다
노드간의 연결을 위해서 만들어지는 network로 외부 포트로 요청이 되면 IPVS 모듈로 전달이 되어서 각 서비스 IP를 추척하여 요쳥을 라우팅한다

ingress network를 통하여 실행중인 컨테이너를 찾아 라우팅이 된다

- **Overlay network**

Overlay Driver를 사용하고 Docker swarm에 있는 Docker Deamon을 연결을 해준다
Overlay network는 외부로 노출이 되지 않으며 내부에서 컨테이너끼리 통신을 한다  
각 서비스는 Overlay network로 연결이 되며 기본값은 default로 지정되어 있어 사용자가 필요에 따라 연결을 원하는 서비스끼리 네트워크를 설정할 수 있다

- **docker_gwbridge**

swarm init, join으로 자동으로 생성이 된다
Docker Daemon의 network에 연결하는 Bridge Network이다
각 컨테이너는 로컬 Docker Daemon Host의 docker_gwbidge network에 연결이 된다

**[참고](https://medium.com/dtevangelist/docker-%EA%B8%B0%EB%B3%B8-8-8-docker%EC%9D%98-network-c75f3077335d)**

![](https://raw.githubusercontent.com/Action2theFuture/Action2theFuture.github.io/main/_posts/Images/overlay2.png)

## Success

- **docker container 일부분**

```
[
    {
        "Id": "8de44ff11272ae00a492941f12446ca391db0e1215d75e1e74fb28ca212f901e",
        "Created": "2021-10-04T16:34:12.961355582Z",
        "Path": "bash",
        "Args": [
            "/app/docker-entrypoint.sh"
        ],
        "State": {
            "Status": "running",
            .
            .
            .
####  Volumes Mount
            "Mounts": [
                {
                    "Type": "bind",
                    "Source": "/var/lib/jenkins/workspace/dockerswarm_test",
                    "Target": "/app"
                }
            ],
####  Overay FileSystem
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/c757cd99f0552ce507e7283fb892bed60c7e3b736fde8cb651674d9ff64292b7-init/diff:/var/lib/docker/overlay2/f74d04f1e1e1d6b20c597d7a29256d5dab38607cf31b34f7556374ff318e5179/.
                .
                .
            },
            "Name": "overlay2"
        },
        "Mounts": [
            {
                "Type": "bind",
                "Source": "/var/lib/jenkins/workspace/dockerswarm_test",
                "Destination": "/app",
                "Mode": "",
                "RW": true,
                "Propagation": "rprivate"
            }
        ],
#### Docker 설정
        "Config": {
            .
            .
            .
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
            ],
            "Cmd": null,
            "Image": "tree0204/drf_tuto:0.1.0@sha256:9b4f63f9eed7c6cebb2582263af13a07bd1e6a919f05837213b0000c56731fab",
            "Volumes": null,
            "WorkingDir": "/app",
            "Entrypoint": [
                "bash",
                "/app/docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {
                "com.docker.stack.namespace": "web",
                "com.docker.swarm.node.id": "ungjqufa2zw1k810nyags3pc6",
                "com.docker.swarm.service.id": "ijgf8zlbody1paunpzpre0s8v",
                "com.docker.swarm.service.name": "web_server",
                "com.docker.swarm.task": "",
                "com.docker.swarm.task.id": "dhg6jc8nrxp1ms7h25rhk7hc5",
                "com.docker.swarm.task.name": "web_server.3.dhg6jc8nrxp1ms7h25rhk7hc5"
            }
        },
        "NetworkSettings": {
            .
            .
            .
            "Networks": {
                "ingress": {
                    "IPAMConfig": {
                        "IPv4Address": "10.0.0.69"
                    },
                    "Links": null,
                    "Aliases": [
                        "8de44ff11272"
                    ],
                    "NetworkID": "fav8krp7vg1bbsyuxou0b2fdn",
                    .
                    .
                    .
                },
                "web_network": {
                    "IPAMConfig": {
                        "IPv4Address": "10.0.2.33"
                    },
                    "Links": null,
                    "Aliases": [
                        "8de44ff11272"
                    ],
                    .
                    .
                    .
                }
            }
        }
    }
]
```

- **network ingress의 일부분**

```
            .
            .
            .
    "Containers": {
                "7593367fb8aa4ceb4832d4e6a5b1e2a6613f7b01bbab094e322d42723498aa81": {
                    "Name": "web_server.2.rz6kyvvzftdingun1a5p0j6ab",
                    "EndpointID": "ba04e3ff8cd76918c0b2fdb07f05934874b5b8c0aa9699c0bf5bc90babdaf99f",
                    "MacAddress": "02:42:0a:00:00:44",
                    "IPv4Address": "10.0.0.68/24",
                    "IPv6Address": ""
                },
                "8de44ff11272ae00a492941f12446ca391db0e1215d75e1e74fb28ca212f901e": {
                    "Name": "web_server.3.dhg6jc8nrxp1ms7h25rhk7hc5",
                    "EndpointID": "85be9b6a62f23ba27b7ab8cc5c9f906943651ec11ae951e30672294885e15a4c",
                    "MacAddress": "02:42:0a:00:00:45",
                    "IPv4Address": "10.0.0.69/24",
                    "IPv6Address": ""
                },
                "912f1d6cd78f1c5e7c9d6dc4089d5006b2027e2f2356d70b95e9f797ee61eec5": {
                    "Name": "web_Swarm_Cluster.1.lxjugwqjwgsc32f7o6asu2gqx",
                    "EndpointID": "19c70af8968754ef96e5407ad0851ca831eb5f4754009e9bae7e0221e1801dc3",
                    "MacAddress": "02:42:0a:00:00:49",
                    "IPv4Address": "10.0.0.73/24",
                    "IPv6Address": ""
                },
                "ff73d49d9b1ff3ba9f33c613255b96db5a8bc3d821cfb57985660f42dae79b11": {
                    "Name": "web_server.1.uokoe0r61hz0ng3ny737t8kgn",
                    "EndpointID": "271b889ff60df690f5ac9d91b8401ab29bc53416139866fc588fc37b93155bca",
                    "MacAddress": "02:42:0a:00:00:46",
                    "IPv4Address": "10.0.0.70/24",
                    "IPv6Address": ""
                },
                "ingress-sbox": {
                    "Name": "ingress-endpoint",
                    "EndpointID": "5a1f3fef51939bf908164612d5679bd0797a72cf2cd888068976bd14c3aaba3a",
                    "MacAddress": "02:42:0a:00:00:02",
                    "IPv4Address": "10.0.0.2/24",
                    "IPv6Address": ""
                }
            .
            .
            .
```

나는 docker swarm을 사용하면서 각 컨테이너가 통신을 하고 의도치않게 꺼진 컨테이너는 다시 활성화가 되어서 서버가 아무런 무리없이 작동하게 되는지가 궁금하였다
